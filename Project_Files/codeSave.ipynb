{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6062feef-546e-4233-8b8d-21bbe02c6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.4819\n",
      "Epoch 2/10, Loss: 0.7306\n",
      "Epoch 3/10, Loss: 0.6921\n",
      "Epoch 4/10, Loss: 0.6897\n",
      "Epoch 5/10, Loss: 0.6747\n",
      "Epoch 6/10, Loss: 0.6601\n",
      "Epoch 7/10, Loss: 0.6385\n",
      "Epoch 8/10, Loss: 0.5526\n",
      "Epoch 9/10, Loss: 0.4907\n",
      "Epoch 10/10, Loss: 0.4332\n",
      "Test Accuracy: 62.00%\n",
      "\n",
      "Extracted Text:\n",
      "We —quide—roun\n",
      "e—Ayide. oven _fox_ jumped, —\n",
      "Treaauie bibvrp a :\n",
      "120 Cay es |\n",
      "pre recon\n",
      "\n",
      "\n",
      "Text structure appears typical.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytesseract  # OCR for text extraction\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "# Define a custom dataset class\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Simple CNN Model for classification\n",
    "class DysgraphiaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DysgraphiaCNN, self).__init__()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 2)  # Binary classification: Dysgraphic / Non-Dysgraphic\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Load dataset paths and labels (simulate CSV for now)\n",
    "data_dir = 'dysgraphiaData/'  # Folder containing images\n",
    "metadata = pd.read_csv('labels.csv')  # CSV with columns: filename, label (0/1)\n",
    "\n",
    "image_paths = [os.path.join(data_dir, fname) for fname in metadata['filename']]\n",
    "labels = metadata['label'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = HandwritingDataset(X_train, y_train, transform=transform)\n",
    "test_dataset = HandwritingDataset(X_test, y_test, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DysgraphiaCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Function for OCR and neurological insights with enhanced preprocessing\n",
    "def analyze_handwriting(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Enhanced Preprocessing\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    morphed = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    cleaned = cv2.dilate(morphed, kernel, iterations=1)\n",
    "\n",
    "    # OCR Extraction\n",
    "    config = r'--oem 3 --psm 6'\n",
    "    text = pytesseract.image_to_string(cleaned, config=config)\n",
    "\n",
    "    print(\"\\nExtracted Text:\")\n",
    "    print(text)\n",
    "\n",
    "    # Example pattern analysis for neurological conditions (simplified)\n",
    "    if any(char.isdigit() for char in text) and len(text.split()) < 3:\n",
    "        print(\"\\nPotential cognitive irregularities detected (e.g., low word count, numeric confusion).\")\n",
    "    elif len(text.strip()) == 0:\n",
    "        print(\"\\nNo readable text detected — may indicate severe motor issues.\")\n",
    "    else:\n",
    "        print(\"\\nText structure appears typical.\")\n",
    "\n",
    "# Example usage\n",
    "sample_image = 'image2.png'\n",
    "analyze_handwriting(sample_image)  # Run OCR and basic insight analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38b884-c3ba-42ed-b890-ca6312661e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
